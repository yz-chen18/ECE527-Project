train_loss,validation_loss
1.5865283771623315,1.542002867217417
1.586198704563548,1.5417599672520603
1.5862536473229978,1.5416739740305476
1.5874743427726896,1.5421958929962583
1.5862400392092022,1.5422599911689758
1.587101249227391,1.541837458257322
1.5864639893485333,1.5424740082687802
1.588540480820043,1.544416002377316
1.5875962127665633,1.5418369516178414
1.5870691888431938,1.5418636658125453
1.585438122605503,1.5417936035880335
1.5888203646633299,1.5425517059586666
1.588476627442787,1.5419150486036584
1.5888850575533378,1.5418754393855731
1.587063684126064,1.5419368296861649
1.58694493307315,1.5423245507257957
1.5871217853785113,1.5427504766870428
1.5885607342985555,1.5420515769057803
1.5901940247852122,1.5419385739498668
1.5866813901682189,1.5428650958670511
1.5858513759902901,1.5418415235148535
1.5859730965576704,1.542021366181197
1.5854426709515865,1.5418464718041596
